{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Ada-FracBNN Testing Notebook\n",
        "\n",
        "This notebook provides an interactive environment to test and explore the Adaptive FracBNN (Ada-FracBNN) implementation.\n",
        "\n",
        "## Features:\n",
        "1. **Baseline FracBNN** - Original FracBNN with fixed gates\n",
        "2. **Adaptive PG** - Learnable per-channel fractionalization\n",
        "3. **Knowledge Distillation** - KD from compact FP teacher\n",
        "\n",
        "## Quick Start:\n",
        "Run cells sequentially to:\n",
        "- Load and configure models\n",
        "- Test on CIFAR-10 dataset\n",
        "- Visualize gate statistics\n",
        "- Compare model performance\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Setup and Imports\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from tqdm.notebook import tqdm\n",
        "import os\n",
        "import sys\n",
        "\n",
        "# Add project root to path\n",
        "project_root = os.path.abspath('.')\n",
        "if project_root not in sys.path:\n",
        "    sys.path.insert(0, project_root)\n",
        "\n",
        "# Import project modules\n",
        "import utils.utils as util\n",
        "import utils.quantization as q\n",
        "import model.fracbnn_cifar10 as m\n",
        "\n",
        "# Set style\n",
        "sns.set_style('whitegrid')\n",
        "plt.rcParams['figure.figsize'] = (12, 6)\n",
        "\n",
        "print(\"PyTorch version:\", torch.__version__)\n",
        "print(\"CUDA available:\", torch.cuda.is_available())\n",
        "if torch.cuda.is_available():\n",
        "    print(\"CUDA device:\", torch.cuda.get_device_name(0))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Configuration\n",
        "config = {\n",
        "    'device': 'cuda' if torch.cuda.is_available() else 'cpu',\n",
        "    'batch_size': 128,\n",
        "    'num_workers': 2,\n",
        "    'data_dir': './data/cifar10',\n",
        "    \n",
        "    # Adaptive PG parameters\n",
        "    'target_sparsity': 0.15,  # Target 15% sparsity (85% of channels use 1-bit)\n",
        "    'sparsity_weight': 0.01,   # Weight for sparsity regularization\n",
        "    \n",
        "    # Knowledge Distillation parameters\n",
        "    'kd_temperature': 4.0,\n",
        "    'kd_alpha': 0.7,\n",
        "    \n",
        "    # Training parameters\n",
        "    'learning_rate': 1e-3,\n",
        "    'num_epochs': 5,  # Small number for quick testing\n",
        "}\n",
        "\n",
        "print(\"Configuration:\")\n",
        "for key, value in config.items():\n",
        "    print(f\"  {key}: {value}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_cifar10(config, normalize=False):\n",
        "    \"\"\"Load CIFAR-10 dataset\"\"\"\n",
        "    transform_list = [transforms.ToTensor()]\n",
        "    \n",
        "    if normalize:\n",
        "        normalize_transform = transforms.Normalize(\n",
        "            mean=[0.485, 0.456, 0.406],\n",
        "            std=[0.229, 0.224, 0.225]\n",
        "        )\n",
        "        transform_list.append(normalize_transform)\n",
        "    \n",
        "    transform_train = transforms.Compose([\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.RandomCrop(32, 4),\n",
        "    ] + transform_list)\n",
        "    \n",
        "    transform_test = transforms.Compose(transform_list)\n",
        "    \n",
        "    trainset = torchvision.datasets.CIFAR10(\n",
        "        root=config['data_dir'],\n",
        "        train=True,\n",
        "        download=True,\n",
        "        transform=transform_train\n",
        "    )\n",
        "    \n",
        "    testset = torchvision.datasets.CIFAR10(\n",
        "        root=config['data_dir'],\n",
        "        train=False,\n",
        "        download=True,\n",
        "        transform=transform_test\n",
        "    )\n",
        "    \n",
        "    trainloader = torch.utils.data.DataLoader(\n",
        "        trainset,\n",
        "        batch_size=config['batch_size'],\n",
        "        shuffle=True,\n",
        "        num_workers=config['num_workers'],\n",
        "        pin_memory=True,\n",
        "        drop_last=True  # Required for binary input encoder\n",
        "    )\n",
        "    \n",
        "    testloader = torch.utils.data.DataLoader(\n",
        "        testset,\n",
        "        batch_size=config['batch_size'],\n",
        "        shuffle=False,\n",
        "        num_workers=config['num_workers'],\n",
        "        pin_memory=True,\n",
        "        drop_last=True\n",
        "    )\n",
        "    \n",
        "    classes = ('plane', 'car', 'bird', 'cat', 'deer',\n",
        "               'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "    \n",
        "    return trainloader, testloader, classes\n",
        "\n",
        "# Load data\n",
        "print(\"Loading CIFAR-10 dataset...\")\n",
        "trainloader, testloader, classes = load_cifar10(config)\n",
        "print(f\"Training batches: {len(trainloader)}\")\n",
        "print(f\"Testing batches: {len(testloader)}\")\n",
        "print(f\"Classes: {classes}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Model Creation and Testing\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_baseline_model(config):\n",
        "    \"\"\"Create baseline FracBNN model (binput-pg)\"\"\"\n",
        "    model = m.resnet20(\n",
        "        batch_size=config['batch_size'],\n",
        "        num_gpus=torch.cuda.device_count()\n",
        "    )\n",
        "    return model\n",
        "\n",
        "def create_adaptive_pg_model(config):\n",
        "    \"\"\"Create Adaptive PG model (adaptive-pg)\"\"\"\n",
        "    model = m.resnet20(\n",
        "        batch_size=config['batch_size'],\n",
        "        num_gpus=torch.cuda.device_count(),\n",
        "        adaptive_pg=True,\n",
        "        target_sparsity=config['target_sparsity']\n",
        "    )\n",
        "    return model\n",
        "\n",
        "def create_teacher_model():\n",
        "    \"\"\"Create FP teacher model for knowledge distillation\"\"\"\n",
        "    model = m.fp_resnet20(num_classes=10)\n",
        "    return model\n",
        "\n",
        "# Test baseline model\n",
        "print(\"Creating Baseline FracBNN model...\")\n",
        "baseline_model = create_baseline_model(config)\n",
        "baseline_model = baseline_model.to(config['device'])\n",
        "print(f\"âœ“ Baseline model created\")\n",
        "print(f\"  Parameters: {sum(p.numel() for p in baseline_model.parameters()):,}\")\n",
        "\n",
        "# Test adaptive PG model\n",
        "print(\"\\nCreating Adaptive PG model...\")\n",
        "adaptive_model = create_adaptive_pg_model(config)\n",
        "adaptive_model = adaptive_model.to(config['device'])\n",
        "print(f\"âœ“ Adaptive PG model created\")\n",
        "print(f\"  Parameters: {sum(p.numel() for p in adaptive_model.parameters()):,}\")\n",
        "\n",
        "# Test forward pass\n",
        "test_images, test_labels = next(iter(testloader))\n",
        "test_images = test_images.to(config['device'])\n",
        "test_labels = test_labels.to(config['device'])\n",
        "\n",
        "print(\"\\nâœ“ Testing forward pass...\")\n",
        "baseline_model.eval()\n",
        "with torch.no_grad():\n",
        "    baseline_output = baseline_model(test_images)\n",
        "print(f\"  Baseline output shape: {baseline_output.shape}\")\n",
        "\n",
        "adaptive_model.eval()\n",
        "with torch.no_grad():\n",
        "    adaptive_output = adaptive_model(test_images)\n",
        "print(f\"  Adaptive output shape: {adaptive_output.shape}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Analyze Adaptive PG Gates\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def analyze_adaptive_gates(model, config):\n",
        "    \"\"\"Analyze and visualize adaptive PG gates\"\"\"\n",
        "    if not hasattr(model, 'get_gate_statistics'):\n",
        "        print(\"Model does not have adaptive gates.\")\n",
        "        return\n",
        "    \n",
        "    gate_stats = model.get_gate_statistics()\n",
        "    \n",
        "    if not gate_stats:\n",
        "        print(\"No gate statistics available.\")\n",
        "        return\n",
        "    \n",
        "    # Extract statistics\n",
        "    layer_names = []\n",
        "    active_fractions = []\n",
        "    gate_means = []\n",
        "    gate_stds = []\n",
        "    \n",
        "    for stats in gate_stats:\n",
        "        layer_names.append(stats['layer_name'])\n",
        "        active_fractions.append(stats['active_fraction'])\n",
        "        gate_means.append(stats['gate_mean'])\n",
        "        gate_stds.append(stats['gate_std'])\n",
        "    \n",
        "    # Print statistics\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"ADAPTIVE PG GATE ANALYSIS\")\n",
        "    print(\"=\"*60)\n",
        "    \n",
        "    for i, name in enumerate(layer_names):\n",
        "        print(f\"\\n{name}:\")\n",
        "        print(f\"  2-bit fraction: {active_fractions[i]:.3f}\")\n",
        "        print(f\"  Gate mean: {gate_means[i]:.3f}\")\n",
        "        print(f\"  Gate std: {gate_stds[i]:.3f}\")\n",
        "    \n",
        "    avg_active = np.mean(active_fractions)\n",
        "    print(f\"\\nOverall 2-bit fraction: {avg_active:.3f}\")\n",
        "    print(f\"Target sparsity: {config['target_sparsity']:.3f}\")\n",
        "    print(f\"Actual sparsity: {1.0 - avg_active:.3f}\")\n",
        "    \n",
        "    # Visualization\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "    \n",
        "    # Plot 1: 2-bit fraction per layer\n",
        "    axes[0].bar(range(len(layer_names)), active_fractions, alpha=0.7)\n",
        "    axes[0].axhline(y=config['target_sparsity'], color='r', linestyle='--',\n",
        "                    label=f\"Target: {config['target_sparsity']:.2f}\")\n",
        "    axes[0].axhline(y=avg_active, color='g', linestyle='--',\n",
        "                    label=f\"Average: {avg_active:.2f}\")\n",
        "    axes[0].set_xlabel('Layer')\n",
        "    axes[0].set_ylabel('2-bit Fraction')\n",
        "    axes[0].set_title('2-bit Fraction per Layer')\n",
        "    axes[0].set_xticks(range(len(layer_names)))\n",
        "    axes[0].set_xticklabels([name.split('.')[-1] for name in layer_names],\n",
        "                            rotation=45, ha='right')\n",
        "    axes[0].legend()\n",
        "    axes[0].grid(True, alpha=0.3)\n",
        "    \n",
        "    # Plot 2: Gate mean and std\n",
        "    x = np.arange(len(layer_names))\n",
        "    width = 0.35\n",
        "    axes[1].bar(x - width/2, gate_means, width, label='Mean', alpha=0.7)\n",
        "    axes[1].bar(x + width/2, gate_stds, width, label='Std', alpha=0.7)\n",
        "    axes[1].set_xlabel('Layer')\n",
        "    axes[1].set_ylabel('Value')\n",
        "    axes[1].set_title('Gate Statistics')\n",
        "    axes[1].set_xticks(x)\n",
        "    axes[1].set_xticklabels([name.split('.')[-1] for name in layer_names],\n",
        "                            rotation=45, ha='right')\n",
        "    axes[1].legend()\n",
        "    axes[1].grid(True, alpha=0.3)\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    return gate_stats\n",
        "\n",
        "# Analyze adaptive model gates\n",
        "gate_stats = analyze_adaptive_gates(adaptive_model, config)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Quick Evaluation Functions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def evaluate_model(model, dataloader, device, desc=\"Evaluating\", max_batches=None):\n",
        "    \"\"\"Evaluate model accuracy\"\"\"\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for i, (images, labels) in enumerate(tqdm(dataloader, desc=desc)):\n",
        "            if max_batches and i >= max_batches:\n",
        "                break\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    \n",
        "    accuracy = 100.0 * correct / total\n",
        "    return accuracy\n",
        "\n",
        "# Quick evaluation on subset\n",
        "print(\"Quick evaluation (first 10 batches)...\")\n",
        "baseline_acc = evaluate_model(baseline_model, testloader, config['device'], \n",
        "                               \"Baseline\", max_batches=10)\n",
        "print(f\"Baseline FracBNN: {baseline_acc:.2f}%\")\n",
        "\n",
        "adaptive_acc = evaluate_model(adaptive_model, testloader, config['device'],\n",
        "                              \"Adaptive\", max_batches=10)\n",
        "print(f\"Adaptive PG: {adaptive_acc:.2f}%\")\n",
        "\n",
        "print(\"\\n(Note: These are random initialization results)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Summary and Full Training Commands\n",
        "\n",
        "### âœ… Test Summary:\n",
        "- Successfully loaded CIFAR-10 dataset\n",
        "- Created and tested Baseline and Adaptive PG models\n",
        "- Verified forward pass works correctly\n",
        "- Analyzed adaptive gate statistics\n",
        "- Quick evaluation completed\n",
        "\n",
        "### ðŸš€ For Full Training, Use Command Line:\n",
        "\n",
        "```bash\n",
        "# 1. Baseline FracBNN (250 epochs)\n",
        "python cifar10.py -id 0 -e 250 -b 128 -g 0.0 -s\n",
        "\n",
        "# 2. Adaptive PG (Ada-FracBNN)\n",
        "python cifar10.py -id 1 -e 250 -b 128 -ts 0.15 -sw 0.01 -s\n",
        "\n",
        "# 3. Adaptive PG + Knowledge Distillation\n",
        "python cifar10.py -id 2 -e 250 -b 128 -ts 0.15 -sw 0.01 \\\\\n",
        "    -temp 4.0 -alpha 0.7 -tp teacher.pth -s\n",
        "```\n",
        "\n",
        "### ðŸ“Š Parameter Guide:\n",
        "- `-id`: Model ID (0=baseline, 1=adaptive-pg, 2=adaptive-pg-kd)\n",
        "- `-e`: Number of epochs\n",
        "- `-b`: Batch size\n",
        "- `-ts`: Target sparsity (0.15 = 15%)\n",
        "- `-sw`: Sparsity regularization weight\n",
        "- `-temp`: KD temperature\n",
        "- `-alpha`: KD loss weight\n",
        "- `-tp`: Teacher model path\n",
        "- `-s`: Save model\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}

{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Ada-FracBNN Testing Notebook (Google Colab Version)\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/YOUR_USERNAME/endingengineering/blob/main/test_ada_fracbnn_colab.ipynb)\n",
        "\n",
        "This notebook is optimized for Google Colab with GPU support.\n",
        "\n",
        "## ‚ö†Ô∏è Important First Steps:\n",
        "1. **Enable GPU**: `Runtime` ‚Üí `Change runtime type` ‚Üí `Hardware accelerator: GPU`\n",
        "2. **Run Cell 1**: Sets up the environment (clone repo, install packages)\n",
        "3. **Run remaining cells** sequentially\n",
        "\n",
        "## Features:\n",
        "- Automatic environment setup for Colab\n",
        "- GPU detection and verification\n",
        "- Google Drive integration for saving models\n",
        "- Optimized batch sizes for Colab GPUs\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üöÄ Step 0: Google Colab Setup (RUN THIS FIRST!)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================\n",
        "# GOOGLE COLAB ENVIRONMENT SETUP\n",
        "# ============================================\n",
        "\n",
        "import sys\n",
        "import os\n",
        "\n",
        "# Detect if running in Colab\n",
        "try:\n",
        "    import google.colab\n",
        "    IN_COLAB = True\n",
        "    print(\"‚úì Running in Google Colab\")\n",
        "except:\n",
        "    IN_COLAB = False\n",
        "    print(\"‚úì Running locally\")\n",
        "\n",
        "if IN_COLAB:\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"SETTING UP GOOGLE COLAB ENVIRONMENT\")\n",
        "    print(\"=\"*60)\n",
        "    \n",
        "    # Check GPU\n",
        "    import torch\n",
        "    if torch.cuda.is_available():\n",
        "        print(f\"\\n‚úì GPU DETECTED: {torch.cuda.get_device_name(0)}\")\n",
        "        print(f\"  CUDA Version: {torch.version.cuda}\")\n",
        "        print(f\"  PyTorch Version: {torch.__version__}\")\n",
        "    else:\n",
        "        print(\"\\n‚ö†Ô∏è  WARNING: GPU NOT DETECTED!\")\n",
        "        print(\"   Go to: Runtime ‚Üí Change runtime type ‚Üí Hardware accelerator: GPU\")\n",
        "        print(\"   Then restart this notebook.\")\n",
        "    \n",
        "    # Clone repository\n",
        "    print(\"\\nüì¶ Cloning repository...\")\n",
        "    # Replace 'YOUR_USERNAME' with your GitHub username\n",
        "    repo_url = \"https://github.com/YOUR_USERNAME/endingengineering.git\"\n",
        "    \n",
        "    # Alternative: Upload files manually\n",
        "    print(\"   Option 1: Clone from GitHub (recommended)\")\n",
        "    print(f\"   !git clone {repo_url}\")\n",
        "    print(\"\\n   Option 2: Upload files manually\")\n",
        "    print(\"   Uncomment the lines below to upload a zip file:\")\n",
        "    print(\"\"\"\n",
        "    # from google.colab import files\n",
        "    # uploaded = files.upload()  # Upload your project.zip\n",
        "    # !unzip -q project.zip\n",
        "    \"\"\")\n",
        "    \n",
        "    # For now, clone (you can modify this)\n",
        "    # !git clone {repo_url}\n",
        "    \n",
        "    # Alternative: Upload files\n",
        "    print(\"\\nüìÅ Please choose setup method:\")\n",
        "    print(\"   A) Clone from GitHub - modify repo_url above and uncomment git clone\")\n",
        "    print(\"   B) Upload files - uncomment the upload code above\")\n",
        "    print(\"\\n‚ö†Ô∏è  After setup, uncomment the appropriate section and rerun this cell\")\n",
        "    \n",
        "    # Uncomment ONE of these:\n",
        "    # Method A: GitHub clone\n",
        "    # !git clone https://github.com/YOUR_USERNAME/endingengineering.git\n",
        "    # %cd endingengineering\n",
        "    \n",
        "    # Method B: Manual upload\n",
        "    # from google.colab import files\n",
        "    # import zipfile\n",
        "    # uploaded = files.upload()\n",
        "    # for f in uploaded.keys():\n",
        "    #     if f.endswith('.zip'):\n",
        "    #         !unzip -q {f}\n",
        "    #         dir_name = f.replace('.zip', '')\n",
        "    #         %cd {dir_name}\n",
        "    \n",
        "    # Install dependencies\n",
        "    print(\"\\nüìö Installing dependencies...\")\n",
        "    !pip install -q tqdm seaborn\n",
        "    \n",
        "    # Mount Google Drive for saving models\n",
        "    print(\"\\nüíæ Mounting Google Drive (optional - for saving models)...\")\n",
        "    print(\"   This allows you to save trained models permanently.\")\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive', force_remount=False)\n",
        "    \n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"‚úÖ SETUP COMPLETE!\")\n",
        "    print(\"=\"*60)\n",
        "    print(\"\\nYou can now run the remaining cells.\")\n",
        "    print(\"Note: Make sure to uncomment the setup method above on first run!\")\n",
        "    \n",
        "else:\n",
        "    print(\"Running locally - no Colab setup needed.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Setup and Imports\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from tqdm.notebook import tqdm\n",
        "import os\n",
        "import sys\n",
        "\n",
        "# Add project root to path (works for both Colab and local)\n",
        "try:\n",
        "    import google.colab\n",
        "    # Colab paths\n",
        "    if os.path.exists('/content/endingengineering'):\n",
        "        sys.path.insert(0, '/content/endingengineering')\n",
        "    project_root = '/content/endingengineering'\n",
        "except:\n",
        "    # Local paths\n",
        "    project_root = os.path.abspath('.')\n",
        "    if project_root not in sys.path:\n",
        "        sys.path.insert(0, project_root)\n",
        "\n",
        "# Import project modules\n",
        "import utils.utils as util\n",
        "import utils.quantization as q\n",
        "import model.fracbnn_cifar10 as m\n",
        "\n",
        "# Set style\n",
        "sns.set_style('whitegrid')\n",
        "plt.rcParams['figure.figsize'] = (12, 6)\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"ENVIRONMENT CHECK\")\n",
        "print(\"=\"*60)\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"CUDA device: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.2f} GB\")\n",
        "print(f\"Working directory: {os.getcwd()}\")\n",
        "print(\"=\"*60)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Configuration (Optimized for Colab)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Configuration (optimized for Google Colab)\n",
        "try:\n",
        "    import google.colab\n",
        "    IN_COLAB = True\n",
        "    data_dir = '/content/data/cifar10'\n",
        "    batch_size = 256  # Larger batch for Colab GPU\n",
        "    save_dir = '/content/drive/MyDrive/ada_fracbnn_models/'\n",
        "except:\n",
        "    IN_COLAB = False\n",
        "    data_dir = './data/cifar10'\n",
        "    batch_size = 128\n",
        "    save_dir = './saved_models/'\n",
        "\n",
        "config = {\n",
        "    'device': 'cuda' if torch.cuda.is_available() else 'cpu',\n",
        "    'batch_size': batch_size,\n",
        "    'num_workers': 2,  # Optimal for Colab\n",
        "    'data_dir': data_dir,\n",
        "    'save_dir': save_dir,\n",
        "    \n",
        "    # Adaptive PG parameters\n",
        "    'target_sparsity': 0.15,  # Target 15% sparsity (85% of channels use 1-bit)\n",
        "    'sparsity_weight': 0.01,   # Weight for sparsity regularization\n",
        "    \n",
        "    # Knowledge Distillation parameters\n",
        "    'kd_temperature': 4.0,\n",
        "    'kd_alpha': 0.7,\n",
        "    \n",
        "    # Training parameters\n",
        "    'learning_rate': 1e-3,\n",
        "    'num_epochs': 5,  # Small number for quick testing\n",
        "}\n",
        "\n",
        "# Create save directory\n",
        "os.makedirs(config['save_dir'], exist_ok=True)\n",
        "\n",
        "print(\"Configuration:\")\n",
        "print(f\"  Environment: {'Google Colab' if IN_COLAB else 'Local'}\")\n",
        "for key, value in config.items():\n",
        "    print(f\"  {key}: {value}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Load CIFAR-10 Dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_cifar10(config, normalize=False):\n",
        "    \"\"\"Load CIFAR-10 dataset\"\"\"\n",
        "    transform_list = [transforms.ToTensor()]\n",
        "    \n",
        "    if normalize:\n",
        "        normalize_transform = transforms.Normalize(\n",
        "            mean=[0.485, 0.456, 0.406],\n",
        "            std=[0.229, 0.224, 0.225]\n",
        "        )\n",
        "        transform_list.append(normalize_transform)\n",
        "    \n",
        "    transform_train = transforms.Compose([\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.RandomCrop(32, 4),\n",
        "    ] + transform_list)\n",
        "    \n",
        "    transform_test = transforms.Compose(transform_list)\n",
        "    \n",
        "    trainset = torchvision.datasets.CIFAR10(\n",
        "        root=config['data_dir'],\n",
        "        train=True,\n",
        "        download=True,\n",
        "        transform=transform_train\n",
        "    )\n",
        "    \n",
        "    testset = torchvision.datasets.CIFAR10(\n",
        "        root=config['data_dir'],\n",
        "        train=False,\n",
        "        download=True,\n",
        "        transform=transform_test\n",
        "    )\n",
        "    \n",
        "    trainloader = torch.utils.data.DataLoader(\n",
        "        trainset,\n",
        "        batch_size=config['batch_size'],\n",
        "        shuffle=True,\n",
        "        num_workers=config['num_workers'],\n",
        "        pin_memory=True,\n",
        "        drop_last=True\n",
        "    )\n",
        "    \n",
        "    testloader = torch.utils.data.DataLoader(\n",
        "        testset,\n",
        "        batch_size=config['batch_size'],\n",
        "        shuffle=False,\n",
        "        num_workers=config['num_workers'],\n",
        "        pin_memory=True,\n",
        "        drop_last=True\n",
        "    )\n",
        "    \n",
        "    classes = ('plane', 'car', 'bird', 'cat', 'deer',\n",
        "               'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "    \n",
        "    return trainloader, testloader, classes\n",
        "\n",
        "print(\"Loading CIFAR-10 dataset...\")\n",
        "trainloader, testloader, classes = load_cifar10(config)\n",
        "print(f\"‚úì Training batches: {len(trainloader)}\")\n",
        "print(f\"‚úì Testing batches: {len(testloader)}\")\n",
        "print(f\"‚úì Classes: {classes}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_baseline_model(config):\n",
        "    \"\"\"Create baseline FracBNN model\"\"\"\n",
        "    model = m.resnet20(\n",
        "        batch_size=config['batch_size'],\n",
        "        num_gpus=torch.cuda.device_count()\n",
        "    )\n",
        "    return model\n",
        "\n",
        "def create_adaptive_pg_model(config):\n",
        "    \"\"\"Create Adaptive PG model\"\"\"\n",
        "    model = m.resnet20(\n",
        "        batch_size=config['batch_size'],\n",
        "        num_gpus=torch.cuda.device_count(),\n",
        "        adaptive_pg=True,\n",
        "        target_sparsity=config['target_sparsity']\n",
        "    )\n",
        "    return model\n",
        "\n",
        "print(\"Creating models...\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Baseline model\n",
        "print(\"\\n1Ô∏è‚É£ Baseline FracBNN\")\n",
        "baseline_model = create_baseline_model(config).to(config['device'])\n",
        "print(f\"   ‚úì Created | Parameters: {sum(p.numel() for p in baseline_model.parameters()):,}\")\n",
        "\n",
        "# Adaptive PG model\n",
        "print(\"\\n2Ô∏è‚É£ Adaptive PG (Ada-FracBNN)\")\n",
        "adaptive_model = create_adaptive_pg_model(config).to(config['device'])\n",
        "print(f\"   ‚úì Created | Parameters: {sum(p.numel() for p in adaptive_model.parameters()):,}\")\n",
        "\n",
        "# Test forward pass\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"Testing forward pass...\")\n",
        "test_images, test_labels = next(iter(testloader))\n",
        "test_images = test_images.to(config['device'])\n",
        "\n",
        "baseline_model.eval()\n",
        "with torch.no_grad():\n",
        "    out1 = baseline_model(test_images)\n",
        "print(f\"‚úì Baseline output: {out1.shape}\")\n",
        "\n",
        "adaptive_model.eval()\n",
        "with torch.no_grad():\n",
        "    out2 = adaptive_model(test_images)\n",
        "print(f\"‚úì Adaptive output: {out2.shape}\")\n",
        "\n",
        "print(\"\\n‚úÖ All models working correctly!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Analyze Adaptive PG Gates üìä\n",
        "\n",
        "Visualize the learnable gates that control 2-bit upgrades\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def analyze_gates(model, config):\n",
        "    \"\"\"Analyze and visualize gates\"\"\"\n",
        "    if not hasattr(model, 'get_gate_statistics'):\n",
        "        print(\"‚ö†Ô∏è Model doesn't have adaptive gates\")\n",
        "        return\n",
        "    \n",
        "    gate_stats = model.get_gate_statistics()\n",
        "    if not gate_stats:\n",
        "        print(\"‚ö†Ô∏è No gate statistics available\")\n",
        "        return\n",
        "    \n",
        "    # Extract data\n",
        "    names = [s['layer_name'] for s in gate_stats]\n",
        "    active = [s['active_fraction'] for s in gate_stats]\n",
        "    means = [s['gate_mean'] for s in gate_stats]\n",
        "    stds = [s['gate_std'] for s in gate_stats]\n",
        "    \n",
        "    # Print stats\n",
        "    print(\"=\"*60)\n",
        "    print(\"ADAPTIVE PG GATE ANALYSIS\")\n",
        "    print(\"=\"*60)\n",
        "    for i, name in enumerate(names):\n",
        "        print(f\"{name}: 2-bit={active[i]:.3f}, mean={means[i]:.3f}, std={stds[i]:.3f}\")\n",
        "    \n",
        "    avg = np.mean(active)\n",
        "    print(f\"\\nüìä Average 2-bit fraction: {avg:.3f}\")\n",
        "    print(f\"üéØ Target sparsity: {config['target_sparsity']:.3f}\")\n",
        "    print(f\"üìâ Actual sparsity: {1.0-avg:.3f}\")\n",
        "    \n",
        "    # Visualize\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "    \n",
        "    # Plot 1: Active fractions\n",
        "    axes[0].bar(range(len(names)), active, alpha=0.7, color='steelblue')\n",
        "    axes[0].axhline(config['target_sparsity'], color='r', linestyle='--', \n",
        "                    label=f\"Target: {config['target_sparsity']:.2f}\")\n",
        "    axes[0].axhline(avg, color='g', linestyle='--', label=f\"Avg: {avg:.2f}\")\n",
        "    axes[0].set_xlabel('Layer')\n",
        "    axes[0].set_ylabel('2-bit Fraction')\n",
        "    axes[0].set_title('2-bit Fraction per Layer')\n",
        "    axes[0].set_xticks(range(len(names)))\n",
        "    axes[0].set_xticklabels([n.split('.')[-1] for n in names], rotation=45, ha='right')\n",
        "    axes[0].legend()\n",
        "    axes[0].grid(True, alpha=0.3)\n",
        "    \n",
        "    # Plot 2: Mean/Std\n",
        "    x = np.arange(len(names))\n",
        "    width = 0.35\n",
        "    axes[1].bar(x - width/2, means, width, label='Mean', alpha=0.7, color='orange')\n",
        "    axes[1].bar(x + width/2, stds, width, label='Std', alpha=0.7, color='purple')\n",
        "    axes[1].set_xlabel('Layer')\n",
        "    axes[1].set_ylabel('Value')\n",
        "    axes[1].set_title('Gate Statistics')\n",
        "    axes[1].set_xticks(x)\n",
        "    axes[1].set_xticklabels([n.split('.')[-1] for n in names], rotation=45, ha='right')\n",
        "    axes[1].legend()\n",
        "    axes[1].grid(True, alpha=0.3)\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Analyze adaptive model\n",
        "analyze_gates(adaptive_model, config)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def quick_eval(model, loader, device, max_batches=10):\n",
        "    \"\"\"Quick evaluation on subset\"\"\"\n",
        "    model.eval()\n",
        "    correct = total = 0\n",
        "    with torch.no_grad():\n",
        "        for i, (imgs, labels) in enumerate(loader):\n",
        "            if i >= max_batches:\n",
        "                break\n",
        "            imgs, labels = imgs.to(device), labels.to(device)\n",
        "            outputs = model(imgs)\n",
        "            _, pred = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (pred == labels).sum().item()\n",
        "    return 100.0 * correct / total\n",
        "\n",
        "print(\"Quick evaluation (10 batches, random weights)...\")\n",
        "print(\"=\"*60)\n",
        "acc1 = quick_eval(baseline_model, testloader, config['device'])\n",
        "print(f\"Baseline FracBNN: {acc1:.2f}%\")\n",
        "\n",
        "acc2 = quick_eval(adaptive_model, testloader, config['device'])\n",
        "print(f\"Adaptive PG: {acc2:.2f}%\")\n",
        "\n",
        "print(\"\\n(Note: ~10% is random chance for 10 classes)\")\n",
        "print(\"After training 250 epochs: ~90-92% accuracy expected\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Full Training (Optional)\n",
        "\n",
        "Run full training for 250 epochs. **Warning**: Takes 8-12 hours!\n",
        "\n",
        "```python\n",
        "# Run this in a new cell if you want full training\n",
        "!python cifar10.py -id 1 -e 250 -b 256 -ts 0.15 -sw 0.01 -s\n",
        "```\n",
        "\n",
        "Or run shorter training for testing (10 epochs):\n",
        "```python\n",
        "!python cifar10.py -id 1 -e 10 -b 256 -ts 0.15 -sw 0.01 -s\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ‚úÖ Summary\n",
        "\n",
        "### What we tested:\n",
        "- ‚úÖ Environment setup (GPU, dependencies)\n",
        "- ‚úÖ CIFAR-10 data loading\n",
        "- ‚úÖ Baseline FracBNN model\n",
        "- ‚úÖ Adaptive PG model with learnable gates\n",
        "- ‚úÖ Forward pass verification\n",
        "- ‚úÖ Gate statistics and visualization\n",
        "- ‚úÖ Quick accuracy evaluation\n",
        "\n",
        "### Next steps:\n",
        "1. üöÄ Run full training (250 epochs)\n",
        "2. üìä Compare baseline vs adaptive performance\n",
        "3. üî¨ Analyze learned gate patterns\n",
        "4. ‚ö° Measure compute savings\n",
        "5. üìù Train with knowledge distillation\n",
        "\n",
        "### Full Training Commands:\n",
        "```bash\n",
        "# Baseline FracBNN\n",
        "!python cifar10.py -id 0 -e 250 -b 256 -g 0.0 -s\n",
        "\n",
        "# Adaptive PG\n",
        "!python cifar10.py -id 1 -e 250 -b 256 -ts 0.15 -sw 0.01 -s\n",
        "\n",
        "# Adaptive PG + KD\n",
        "!python cifar10.py -id 2 -e 250 -b 256 -ts 0.15 -sw 0.01 -temp 4.0 -alpha 0.7 -tp teacher.pth -s\n",
        "```\n",
        "\n",
        "### Save results to Drive:\n",
        "```python\n",
        "# Mount drive (if not already)\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Copy models\n",
        "!cp -r save_CIFAR10_model /content/drive/MyDrive/ada_fracbnn_results/\n",
        "```\n",
        "\n",
        "---\n",
        "**Ready for production training!** üéâ\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
